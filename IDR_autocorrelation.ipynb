{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d4b67d",
   "metadata": {},
   "source": [
    "Code to access the IDR and perform autocorrelation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c248727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "import warnings\n",
    "import omero\n",
    "from idr import connection\n",
    "\n",
    "import requests\n",
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from pandas import concat\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906891a",
   "metadata": {},
   "source": [
    "Access database and build dataframe of image ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae09f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBulkAnnotationAsDf(screenID, conn):\n",
    "    sc = conn.getObject('Screen', screenID)\n",
    "    for ann in sc.listAnnotations():\n",
    "        if isinstance(ann, omero.gateway.FileAnnotationWrapper):\n",
    "            if (ann.getFile().getName() == 'bulk_annotations'):\n",
    "                number = ann.getFile().getSize()\n",
    "                ofId = ann.getFile().getId()\n",
    "                break\n",
    "\n",
    "    original_file = omero.model.OriginalFileI(ofId, False)\n",
    "\n",
    "    table = conn.c.sf.sharedResources().openTable(original_file)\n",
    "    try:\n",
    "        rowCount = table.getNumberOfRows()\n",
    "\n",
    "        column_names = [col.name for col in table.getHeaders()]\n",
    "\n",
    "        black_list = []\n",
    "        column_indices = []\n",
    "        for column_name in column_names:\n",
    "            if column_name in black_list:\n",
    "                continue\n",
    "            column_indices.append(column_names.index(column_name))\n",
    "\n",
    "        table_data = table.slice(column_indices, None)\n",
    "    finally:\n",
    "        table.close()\n",
    "\n",
    "    data = []\n",
    "    for index in range(rowCount):\n",
    "        row_values = [column.values[index] for column in table_data.columns]\n",
    "        data.append(row_values)\n",
    "\n",
    "    dfAnn = DataFrame(data)\n",
    "    dfAnn.columns = column_names\n",
    "    return dfAnn\n",
    "\n",
    "#connect to database\n",
    "conn = connection('idr.openmicroscopy.org')\n",
    "\n",
    "#get annotations for screen\n",
    "df = getBulkAnnotationAsDf(2651, conn)\n",
    "\n",
    "#close the connection\n",
    "conn.close()\n",
    "\n",
    "# extract images that contain T53BP1\n",
    "subDF = df[df['Channels'].str.contains('TP53BP1')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f8f02",
   "metadata": {},
   "source": [
    "Build Image ID dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea51768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract HepG2 cell images\n",
    "HepG2DF = subDF[subDF['Characteristics [Cell Line]'].str.contains('HepG2')]\n",
    "HepG2DF=HepG2DF.drop(HepG2DF.columns[[2,3,4,6,7,10,13,14,15,16,17,18,19,20,21,22]], axis=1)\n",
    "HepG2DF[\"image_id\"] = \"\"\n",
    "HepG2DF[\"DA\"] = np.nan\n",
    "HepG2DF[\"stdev\"] = np.nan\n",
    "HepG2DF[\"count\"] = np.nan\n",
    "# get plates\n",
    "plates = HepG2DF['Plate'].unique()\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import requests\n",
    "# initial data\n",
    "IDR_BASE_URL = \"https://idr.openmicroscopy.org\"\n",
    "\n",
    "INDEX_PAGE = \"%s/webclient/?experimenter=-1\" % IDR_BASE_URL\n",
    "# create http session\n",
    "with requests.Session() as session:\n",
    "    request = requests.Request('GET', INDEX_PAGE)\n",
    "    prepped = session.prepare_request(request)\n",
    "    response = session.send(prepped)\n",
    "    if response.status_code != 200:\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        \n",
    "# get image id number\n",
    "image_id = []\n",
    "well_id = []\n",
    "for i in range(len(plates)):\n",
    "    WELLS_IMAGES_URL = \"{base}/webgateway/plate/{plate_id}/{field}/\"\n",
    "    plate_id = plates[i]\n",
    "    qs = {'base': IDR_BASE_URL, 'plate_id': plate_id, 'field': 0}\n",
    "    url = WELLS_IMAGES_URL.format(**qs)\n",
    "    grid = session.get(url).json()\n",
    "    rowlabels = grid['rowlabels']\n",
    "    collabels = grid['collabels']\n",
    "    for row in grid['grid']:\n",
    "        for cell in row:\n",
    "            if cell is not None:\n",
    "                image2=cell['id']\n",
    "                well2=cell['wellId']\n",
    "                image_id.append(image2)\n",
    "                well_id.append(well2)\n",
    "\n",
    "#finalize DataFrame\n",
    "for i in range(len(image_id)):\n",
    "    HepG2DF.loc[HepG2DF.Well == well_id[i],'image_id'] = image_id[i]\n",
    "    \n",
    "HepG2DF.to_csv(\"HepG2Data.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2b2c0",
   "metadata": {},
   "source": [
    "Perform autocorrelation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4013a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up for ICS analysis\n",
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from glob import glob\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, normalize\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "\n",
    "from stardist import random_label_cmap, _draw_polygons, export_imagej_rois\n",
    "from stardist.models import StarDist2D\n",
    "\n",
    "from PIL import Image\n",
    "import skimage.measure \n",
    "\n",
    "import scipy.optimize as opt\n",
    "from scipy.fftpack import fft2, ifft2\n",
    "\n",
    "np.random.seed(6)\n",
    "lbl_cmap = random_label_cmap()\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# set up functions\n",
    "\n",
    "def autocorrelation(x,intensity) :\n",
    "    f = fft2(x)\n",
    "    fConj = np.conj(f)\n",
    "    p = f*fConj\n",
    "    pi = ifft2(p)\n",
    "    return np.fft.fftshift(np.real(pi)/((intensity**2)*len(x)*len(x[0])))-1\n",
    "\n",
    "def correlationCorrection(x,corr) : \n",
    "    x[x < 0] = 0\n",
    "    y  = x*(1/corr)*9 \n",
    "    return y\n",
    "\n",
    "def func(M,a,b,c) :\n",
    "    x0 = xDim[indFitCrop[0]] # x and y values at peak\n",
    "    y0 = yDim[indFitCrop[1]]\n",
    "    x,y=M\n",
    "    return a*np.exp(-((x-x0)**2 + (y-y0)**2)/c**2)+b\n",
    "\n",
    "def fitCropping(z,h) :\n",
    "    ind = np.unravel_index(np.argmax(z, axis=None), z.shape)\n",
    "    if ind[0] > z.shape[0]-h or ind[1] > z.shape[1]-h or ind[0] < h or ind[1] < h:\n",
    "        return np.zeros((2*h,2*h))\n",
    "    else:\n",
    "        return z[ind[0]-h:ind[0]+h,ind[1]-h:ind[1]+h]\n",
    "    \n",
    "# define constants\n",
    "pixelSize = 0.64\n",
    "cropDim = 10\n",
    "\n",
    "#filters for incorrect fits\n",
    "areaMax = 3000 \n",
    "areaMin = 300 \n",
    "intMax = 3500\n",
    "intMin = 200\n",
    "w0Max = 3\n",
    "w0Min = 0\n",
    "errorLimit = 5\n",
    "nucleiMinCount = 50\n",
    "\n",
    "#constants for fitting\n",
    "xDim = np.linspace(-(cropDim-1),cropDim,cropDim*2)*pixelSize\n",
    "yDim = np.linspace(-(cropDim-1),cropDim,cropDim*2)*pixelSize\n",
    "X,Y=np.meshgrid(xDim,yDim)\n",
    "xdata = np.vstack((X.ravel(), Y.ravel()))\n",
    "initialGuess = (0.8, 0.14, 1.4)\n",
    "\n",
    "model = StarDist2D.from_pretrained('2D_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connection('idr.openmicroscopy.org')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load image\n",
    "for i in range(19357, len(HepG2DF.index)):\n",
    "    imageID = HepG2DF.iloc[i]['image_id']\n",
    "    image = conn.getObject(\"Image\", imageID)\n",
    "    pixels = image.getPrimaryPixels()\n",
    "    dapiMatrix = pixels.getPlane(0, 0, 0)\n",
    "    AbMatrix = pixels.getPlane(0,1,0)\n",
    "    \n",
    "    # run analysis\n",
    "    n_channel = 1 if dapiMatrix.ndim == 2 else dapiMatrix.shape[-1]\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "\n",
    "    #segment DAPI\n",
    "    img = normalize(dapiMatrix, 1,99.8, axis=axis_norm) # dapiMatrix[i]\n",
    "    labels, details = model.predict_instances(img, prob_thresh=0.8)\n",
    "    \n",
    "    # subtract image backgrounds\n",
    "    AbBack = np.percentile(AbMatrix,5) # 5th percentile of image  #AbMatrix[i]\n",
    "    AbImage = np.subtract(AbMatrix,AbBack) #AbMatrix[i]\n",
    "    AbImage[AbImage<0] = 0\n",
    "\n",
    "    #area, ab intensity, bounding box, extent=corrFactor\n",
    "    regions = skimage.measure.regionprops_table(labels,intensity_image=AbImage,properties=('area','intensity_mean','bbox','extent','image'))\n",
    "    nuclei=pd.DataFrame.from_dict(regions)\n",
    "    \n",
    "    #initialize data lists\n",
    "    DAList = []\n",
    "\n",
    "    for k in range(len(nuclei)):\n",
    "    \n",
    "        #get bounding boxes\n",
    "        rowMin = nuclei['bbox-0'][k]\n",
    "        colMin = nuclei['bbox-1'][k]\n",
    "        rowMax = nuclei['bbox-2'][k]\n",
    "        colMax = nuclei['bbox-3'][k]\n",
    "        padRow = rowMax-rowMin\n",
    "        padCol = colMax-colMin\n",
    "        \n",
    "        #Ab speciific\n",
    "        meanInt = np.rint(nuclei.intensity_mean[k])\n",
    "    \n",
    "        crop = AbImage[rowMin:rowMax, colMin:colMax]\n",
    "        cropAve = crop*nuclei.image[k]\n",
    "        cropAve[cropAve == 0] = meanInt\n",
    "        cropPad = np.pad(cropAve,((padRow,padRow),(padCol,padCol)), 'constant',constant_values=meanInt)\n",
    "    \n",
    "        try:\n",
    "            autoCorr = autocorrelation(cropPad,meanInt) # run correlation\n",
    "            autoCorrCorrected = correlationCorrection(autoCorr,nuclei.extent[k]) # correct correlation\n",
    "        \n",
    "            fitCrop = fitCropping(autoCorrCorrected,cropDim) # crop autocorrelation for fitting\n",
    "            indFitCrop = np.unravel_index(np.argmax(fitCrop, axis=None), fitCrop.shape)#find peak in cropped image\n",
    "            popt,pcov = opt.curve_fit(func,xdata,fitCrop.ravel(), p0 = initialGuess) # fit\n",
    "        \n",
    "            # pull out parameters\n",
    "            perr = np.sqrt(np.diag(pcov)) # stdev of fits\n",
    "            relError = perr/popt*100 # percent deviation from measurement\n",
    "            nop = 1/popt[0]\n",
    "            w0 = popt[2]\n",
    "            DA = meanInt/nop\n",
    "            relErrorMax = max(relError[0],relError[2]) #maximum percentDev between g(0,0) and w0\n",
    "            area = nuclei.area[k]\n",
    "            \n",
    "            # filter to remove incorrect results\n",
    "            if area > areaMax or area < areaMin or w0 > w0Max or w0 < w0Min\\\n",
    "            or relErrorMax > errorLimit or len(nuclei) < nucleiMinCount:\n",
    "                DA = np.nan\n",
    "                \n",
    "        except Exception:\n",
    "            DA = np.nan\n",
    "\n",
    "        # add parameters to list\n",
    "        DAList.append(DA)\n",
    "        \n",
    "############## end of nuclear analysis\n",
    "    \n",
    "    #calculate mean and stdev of DA\n",
    "    DAmean=np.nanmean(DAList)\n",
    "    DAstd=np.nanstd(DAList)\n",
    "    DAlimit=DAmean+2*DAstd\n",
    "    replace = np.nan\n",
    "    DAedited = [replace if ele > DAlimit else ele for ele in DAList]\n",
    "    DAfinal=np.nanmean(DAedited)\n",
    "    DAfinalStd=np.nanstd(DAedited)\n",
    "\n",
    "    HepG2DF.loc[HepG2DF.image_id == imageID,'DA'] = DAfinal\n",
    "    HepG2DF.loc[HepG2DF.image_id == imageID,'stdev'] = DAfinalStd\n",
    "    HepG2DF.loc[HepG2DF.image_id == imageID,'count'] = len(nuclei)\n",
    "    \n",
    "    percent=i/len(HepG2DF.index)*100\n",
    "    print(percent)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4972dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42629a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba206609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
